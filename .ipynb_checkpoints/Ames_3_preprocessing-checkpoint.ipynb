{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1afd189",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83729e2",
   "metadata": {},
   "source": [
    "**packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the target encoder\n",
    "te = TargetEncoder(smoothing=5)\n",
    "from category_encoders import BinaryEncoder, TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458a0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder, RobustScaler, MinMaxScaler      # Model Pre-Processing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from category_encoders import BinaryEncoder, TargetEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor    # Regression Models\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from math import sqrt\n",
    "from IPython.display import display, HTML # Display Preferences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971dea2c",
   "metadata": {},
   "source": [
    "**data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bea2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Raw Data\n",
    "data_raw = pd.read_csv('data/Ames_Housing_Price_Data.csv')\n",
    "data_raw.rename(columns={'Unnamed: 0': 'Unnamed 0'}, inplace=True)\n",
    "\n",
    "# columns_to_drop = ['Unnamed: 0'] #'price_per_sqft',\n",
    "# data_raw = data_raw.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4c95d",
   "metadata": {},
   "source": [
    "**display prefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9c6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c25d49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_scroll {\n",
       "    box-sizing: border-box;\n",
       "    display: block;\n",
       "    -webkit-box-sizing: border-box;\n",
       "    -moz-box-sizing: border-box;\n",
       "    max-height: 100px;\n",
       "    overflow: auto;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Max Column and Rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Code Block Output: Enable 100px + scrolling\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_scroll {\n",
    "    box-sizing: border-box;\n",
    "    display: block;\n",
    "    -webkit-box-sizing: border-box;\n",
    "    -moz-box-sizing: border-box;\n",
    "    max-height: 100px;\n",
    "    overflow: auto;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5f04e",
   "metadata": {},
   "source": [
    "**Notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a18cfc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Handling Categorical Variables</th>\n",
       "      <th>Handling Missing Values</th>\n",
       "      <th>Feature Scaling</th>\n",
       "      <th>Dimensionality Reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regularized Linear Regression</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required</td>\n",
       "      <td>Required (especially for models like Lasso and...</td>\n",
       "      <td>Can be beneficial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boosting Models (e.g., XGBoost, LightGBM)</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required (some models like XGBoost can handle ...</td>\n",
       "      <td>Not Required (but can be beneficial in some ca...</td>\n",
       "      <td>Can be beneficial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>Not always necessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Networks</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required</td>\n",
       "      <td>Required (Neural networks are sensitive to fea...</td>\n",
       "      <td>Can be beneficial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machines (SVM)</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required</td>\n",
       "      <td>Required (SVMs are sensitive to feature scale)</td>\n",
       "      <td>Can be beneficial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors (KNN)</td>\n",
       "      <td>Required (One-hot Encoding, Label Encoding, etc.)</td>\n",
       "      <td>Required</td>\n",
       "      <td>Required (KNN is sensitive to feature scale)</td>\n",
       "      <td>Can be beneficial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model  \\\n",
       "0              Regularized Linear Regression   \n",
       "1  Boosting Models (e.g., XGBoost, LightGBM)   \n",
       "2                              Random Forest   \n",
       "3                            Neural Networks   \n",
       "4              Support Vector Machines (SVM)   \n",
       "5                  K-Nearest Neighbors (KNN)   \n",
       "\n",
       "                      Handling Categorical Variables  \\\n",
       "0  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "1  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "2  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "3  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "4  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "5  Required (One-hot Encoding, Label Encoding, etc.)   \n",
       "\n",
       "                             Handling Missing Values  \\\n",
       "0                                           Required   \n",
       "1  Required (some models like XGBoost can handle ...   \n",
       "2                                           Required   \n",
       "3                                           Required   \n",
       "4                                           Required   \n",
       "5                                           Required   \n",
       "\n",
       "                                     Feature Scaling Dimensionality Reduction  \n",
       "0  Required (especially for models like Lasso and...        Can be beneficial  \n",
       "1  Not Required (but can be beneficial in some ca...        Can be beneficial  \n",
       "2                                       Not Required     Not always necessary  \n",
       "3  Required (Neural networks are sensitive to fea...        Can be beneficial  \n",
       "4     Required (SVMs are sensitive to feature scale)        Can be beneficial  \n",
       "5       Required (KNN is sensitive to feature scale)        Can be beneficial  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "model_preprocessing = pd.DataFrame({\n",
    "    'Model': ['Regularized Linear Regression', 'Boosting Models (e.g., XGBoost, LightGBM)', 'Random Forest', 'Neural Networks', 'Support Vector Machines (SVM)', 'K-Nearest Neighbors (KNN)'],\n",
    "    'Handling Categorical Variables': ['Required (One-hot Encoding, Label Encoding, etc.)', 'Required (One-hot Encoding, Label Encoding, etc.)', 'Required (One-hot Encoding, Label Encoding, etc.)', 'Required (One-hot Encoding, Label Encoding, etc.)', 'Required (One-hot Encoding, Label Encoding, etc.)', 'Required (One-hot Encoding, Label Encoding, etc.)'],\n",
    "    'Handling Missing Values': ['Required', 'Required (some models like XGBoost can handle internally)', 'Required', 'Required', 'Required', 'Required'],\n",
    "    'Feature Scaling': ['Required (especially for models like Lasso and Ridge)', 'Not Required (but can be beneficial in some cases, MinMaxScaler)', 'Not Required', 'Required (Neural networks are sensitive to feature scale)', 'Required (SVMs are sensitive to feature scale)', 'Required (KNN is sensitive to feature scale)'],\n",
    "    'Dimensionality Reduction': ['Can be beneficial', 'Can be beneficial', 'Not always necessary', 'Can be beneficial', 'Can be beneficial', 'Can be beneficial']\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "model_preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57af264",
   "metadata": {},
   "source": [
    "## 0. Base Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08ea05",
   "metadata": {},
   "source": [
    "## 1. Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1acd41",
   "metadata": {},
   "source": [
    "**drop unnamed columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb0b3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed 0'] #'price_per_sqft',\n",
    "data_raw = data_raw.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24004ca3",
   "metadata": {},
   "source": [
    "# 2: Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9dc48b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c4914",
   "metadata": {},
   "source": [
    "**encode after split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd34d322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2:  0.9939731835568638\n",
      "Test R2:  0.9425736824173715\n",
      "Train RMSE:  5751.640523457935\n",
      "Test RMSE:  18795.445012139557\n",
      "Train MAE:  4492.233545167931\n",
      "Test MAE:  11681.378556700603\n"
     ]
    }
   ],
   "source": [
    "# Assume that 'SalePrice' is your target column\n",
    "target_encoding = data_raw.copy()\n",
    "X = target_encoding.drop('SalePrice', axis=1)\n",
    "y = target_encoding['SalePrice']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the target encoder\n",
    "te = TargetEncoder(smoothing=5)\n",
    "\n",
    "# Fit the encoder on the training data and transform both the training and test data\n",
    "X_train_encoded = te.fit_transform(X_train, y_train)\n",
    "X_test_encoded = te.transform(X_test)\n",
    "\n",
    "# Initialize the CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on the training and test sets\n",
    "train_predictions = model.predict(X_train_encoded)\n",
    "test_predictions = model.predict(X_test_encoded)\n",
    "\n",
    "# Calculate and print the R2 score, RMSE, and MAE\n",
    "print(\"Train R2: \", r2_score(y_train, train_predictions))\n",
    "print(\"Test R2: \", r2_score(y_test, test_predictions))\n",
    "print(\"Train RMSE: \", sqrt(mean_squared_error(y_train, train_predictions)))\n",
    "print(\"Test RMSE: \", sqrt(mean_squared_error(y_test, test_predictions)))\n",
    "print(\"Train MAE: \", mean_absolute_error(y_train, train_predictions))\n",
    "print(\"Test MAE: \", mean_absolute_error(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3471f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2:  0.9957451903945113\n",
      "Val R2:  0.9284089096365036\n",
      "Test R2:  0.9454605793360498\n",
      "Train RMSE:  4718.2785416957195\n",
      "Val RMSE:  22904.094600137927\n",
      "Test RMSE:  17485.07861131927\n",
      "Train MAE:  3691.3500914557685\n",
      "Val MAE:  12873.2097385998\n",
      "Test RMSE:  11306.61852578595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Assume that 'SalePrice' is your target column\n",
    "target_encoding = data_raw.copy()\n",
    "X = target_encoding.drop('SalePrice', axis=1)\n",
    "y = target_encoding['SalePrice']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # Temp is combined validation + test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split temp into validation and test\n",
    "\n",
    "# Initialize the target encoder\n",
    "te = TargetEncoder(smoothing=5)\n",
    "\n",
    "# Fit the encoder on the training data and transform training, validation, and test data\n",
    "X_train_encoded = te.fit_transform(X_train, y_train)\n",
    "X_val_encoded = te.transform(X_val)\n",
    "X_test_encoded = te.transform(X_test)\n",
    "\n",
    "# Initialize the CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "# Train the model using training and validation sets\n",
    "model.fit(X_train_encoded, y_train, eval_set=(X_val_encoded, y_val))\n",
    "\n",
    "# Make predictions on the training, validation and test sets\n",
    "train_predictions = model.predict(X_train_encoded)\n",
    "val_predictions = model.predict(X_val_encoded)\n",
    "test_predictions = model.predict(X_test_encoded)\n",
    "\n",
    "# Calculate and print the R2 score, RMSE, and MAE\n",
    "print(\"Train R2: \", r2_score(y_train, train_predictions))\n",
    "print(\"Val R2: \", r2_score(y_val, val_predictions))\n",
    "print(\"Test R2: \", r2_score(y_test, test_predictions))\n",
    "print(\"Train RMSE: \", sqrt(mean_squared_error(y_train, train_predictions)))\n",
    "print(\"Val RMSE: \", sqrt(mean_squared_error(y_val, val_predictions)))\n",
    "print(\"Test RMSE: \", sqrt(mean_squared_error(y_test, test_predictions)))\n",
    "print(\"Train MAE: \", mean_absolute_error(y_train, train_predictions))\n",
    "print(\"Val MAE: \", mean_absolute_error(y_val, val_predictions))\n",
    "print(\"Test MAE: \", mean_absolute_error(y_test, test_predictions))\n",
    "\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ef1cb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'depth': 5, 'iterations': 1000, 'learning_rate': 0.05}\n",
      "Best score: 0.915360709991854\n",
      "Train R2:  0.9910002063867195\n",
      "Val R2:  0.9314685015561626\n",
      "Test R2:  0.9448840672379218\n",
      "Train RMSE:  6862.143335107635\n",
      "Val RMSE:  22409.323916657195\n",
      "Test RMSE:  17577.24919498498\n",
      "Train MAE:  5380.085472734284\n",
      "Val MAE:  13101.01293157815\n",
      "Test MAE:  11359.18460822544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01,0.05],\n",
    "    'iterations': [500,1000]\n",
    "}\n",
    "\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best score\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")\n",
    "\n",
    "# Fit the model with the best parameters found\n",
    "model = CatBoostRegressor(**best_params, verbose=0)\n",
    "model.fit(X_train_encoded, y_train, eval_set=(X_val_encoded, y_val))\n",
    "\n",
    "# Continue with your predictions and evaluation\n",
    "\n",
    "# Make predictions on the training, validation and test sets\n",
    "train_predictions = model.predict(X_train_encoded)\n",
    "val_predictions = model.predict(X_val_encoded)\n",
    "test_predictions = model.predict(X_test_encoded)\n",
    "\n",
    "# Calculate and print the R2 score, RMSE, and MAE\n",
    "print(\"Train R2: \", r2_score(y_train, train_predictions))\n",
    "print(\"Val R2: \", r2_score(y_val, val_predictions))\n",
    "print(\"Test R2: \", r2_score(y_test, test_predictions))\n",
    "print(\"Train RMSE: \", sqrt(mean_squared_error(y_train, train_predictions)))\n",
    "print(\"Val RMSE: \", sqrt(mean_squared_error(y_val, val_predictions)))\n",
    "print(\"Test RMSE: \", sqrt(mean_squared_error(y_test, test_predictions)))\n",
    "print(\"Train MAE: \", mean_absolute_error(y_train, train_predictions))\n",
    "print(\"Val MAE: \", mean_absolute_error(y_val, val_predictions))\n",
    "print(\"Test MAE: \", mean_absolute_error(y_test, test_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b81722",
   "metadata": {},
   "source": [
    "**label encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09afbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = data_raw.copy()\n",
    "dummified_encoding = data_raw.copy()\n",
    "ordinal_encoding = data_raw.copy()\n",
    "binary_encoding = data_raw.copy()\n",
    "frequency_encoding = data_raw.copy()\n",
    "target_encoding = data_raw.copy()\n",
    "hashing_encoding = data_raw.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c206ae07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Ordinal Encoding\n",
    "# Note: You need to specify the order of categories for each ordinal feature\n",
    "# oe = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "# ordinal_encoding['Quality'] = oe.fit_transform(ordinal_encoding[['Quality']])\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "for col in label_encoding.columns:\n",
    "    if label_encoding[col].dtype == 'object':\n",
    "        label_encoding[col] = le.fit_transform(label_encoding[col])\n",
    "\n",
    "# Dummified\n",
    "dummified_encoding = pd.get_dummies(dummified_encoding)\n",
    "\n",
    "# Binary Encoding\n",
    "be = BinaryEncoder()\n",
    "binary_encoding = be.fit_transform(binary_encoding)\n",
    "\n",
    "# Frequency Encoding\n",
    "for col in frequency_encoding.columns:\n",
    "    if frequency_encoding[col].dtype == 'object':\n",
    "        freq = frequency_encoding[col].value_counts(normalize=True)\n",
    "        frequency_encoding[col] = frequency_encoding[col].map(freq)\n",
    "\n",
    "# Hashing Encoding\n",
    "fh = FeatureHasher(n_features=10, input_type='string')\n",
    "for col in hashing_encoding.columns:\n",
    "    if hashing_encoding[col].dtype == 'object':\n",
    "        hashed_features = fh.transform(hashing_encoding[[col]].astype(str).values)\n",
    "        hashed_features = pd.DataFrame(hashed_features.toarray(), columns=[f\"{col}_{i}\" for i in range(10)])\n",
    "        hashing_encoding = pd.concat([hashing_encoding, hashed_features], axis=1)\n",
    "        hashing_encoding = hashing_encoding.drop(col, axis=1)\n",
    "\n",
    "# Target Encoding with smoothing\n",
    "te = TargetEncoder(smoothing=10)  # adjust the smoothing parameter as needed\n",
    "for col in target_encoding.drop(columns='SalePrice').columns:\n",
    "    if target_encoding[col].dtype == 'object':\n",
    "        target_encoding[col] = te.fit_transform(target_encoding[col], target_encoding['SalePrice'])\n",
    "        \n",
    "# Backward Difference Encoding\n",
    "backward_difference_encoding = data_raw.copy()\n",
    "encoder = ce.BackwardDifferenceEncoder()\n",
    "backward_difference_encoding = encoder.fit_transform(backward_difference_encoding)\n",
    "\n",
    "# Polynomial Encoding\n",
    "polynomial_encoding = data_raw.copy()\n",
    "encoder = ce.PolynomialEncoder()\n",
    "polynomial_encoding = encoder.fit_transform(polynomial_encoding)\n",
    "\n",
    "# Helmert Encoding\n",
    "helmert_encoding = data_raw.copy()\n",
    "encoder = ce.HelmertEncoder()\n",
    "helmert_encoding = encoder.fit_transform(helmert_encoding)\n",
    "\n",
    "# Sum Encoding\n",
    "sum_encoding = data_raw.copy()\n",
    "encoder = ce.SumEncoder()\n",
    "sum_encoding = encoder.fit_transform(sum_encoding)\n",
    "\n",
    "# One-Hot Encoding with sklearn\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "onehot_encoding_sklearn = data_raw.copy()\n",
    "# Select only the object columns\n",
    "object_cols = onehot_encoding_sklearn.select_dtypes(include='object').columns\n",
    "# Fit and transform the object columns\n",
    "onehot_encoded_cols = ohe.fit_transform(onehot_encoding_sklearn[object_cols])\n",
    "# The output of the transformation is a NumPy array, so we need to convert it back to a DataFrame\n",
    "onehot_encoded_cols_df = pd.DataFrame(onehot_encoded_cols, columns=ohe.get_feature_names_out(object_cols))\n",
    "# Drop the original object columns from the original DataFrame\n",
    "onehot_encoding_sklearn = onehot_encoding_sklearn.drop(object_cols, axis=1)\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "onehot_encoding_sklearn = pd.concat([onehot_encoding_sklearn, onehot_encoded_cols_df], axis=1)\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d2135",
   "metadata": {},
   "source": [
    "**run models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b797068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                                        CatBoost      LightGBM  \\\n",
      "Score      Encoding                                                   \n",
      "Test MAE   Backward Difference Encoding  11913.793600  14151.743678   \n",
      "           Binary Encoding               12202.661443  14145.097757   \n",
      "           Dummified Encoding            12334.491225  13900.037137   \n",
      "           Frequency Encoding            12542.878922  14164.724294   \n",
      "           Hashing Encoding              12731.425122  14402.230365   \n",
      "...                                               ...           ...   \n",
      "Train RMSE Label Encoding                 5967.037485   9211.055605   \n",
      "           One-Hot Encoding               6378.236962   9448.406826   \n",
      "           Polynomial Encoding            5767.284460   9058.071716   \n",
      "           Sum Encoding                   6383.503008   9448.406826   \n",
      "           Target Encoding                5719.821910   9208.087328   \n",
      "\n",
      "Model                                         XGBoost  \n",
      "Score      Encoding                                    \n",
      "Test MAE   Backward Difference Encoding  15572.431890  \n",
      "           Binary Encoding               15404.203670  \n",
      "           Dummified Encoding            15434.297927  \n",
      "           Frequency Encoding            16136.843099  \n",
      "           Hashing Encoding              14746.890466  \n",
      "...                                               ...  \n",
      "Train RMSE Label Encoding                 2016.945240  \n",
      "           One-Hot Encoding               2417.372542  \n",
      "           Polynomial Encoding            2205.357358  \n",
      "           Sum Encoding                   2417.372542  \n",
      "           Target Encoding                2164.905898  \n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"XGBoost\": XGBRegressor()\n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    return {\n",
    "        \"Train R2\": r2_score(y_train, train_predictions),\n",
    "        \"Test R2\": r2_score(y_test, test_predictions),\n",
    "        \"Train RMSE\": sqrt(mean_squared_error(y_train, train_predictions)),\n",
    "        \"Test RMSE\": sqrt(mean_squared_error(y_test, test_predictions)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, train_predictions),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, test_predictions)\n",
    "    }\n",
    "\n",
    "# Define a function to prepare data and evaluate models\n",
    "def prepare_and_evaluate(data):\n",
    "    X = data.drop(columns='SalePrice')\n",
    "    y = data['SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return {name: evaluate_model(model, X_train, X_test, y_train, y_test) for name, model in models.items()}\n",
    "\n",
    "# Prepare data and evaluate models\n",
    "results = {\n",
    "    \"Label Encoding\": prepare_and_evaluate(label_encoding),\n",
    "    \"Dummified Encoding\": prepare_and_evaluate(dummified_encoding),\n",
    "    \"Binary Encoding\": prepare_and_evaluate(binary_encoding),\n",
    "    \"Frequency Encoding\": prepare_and_evaluate(frequency_encoding),\n",
    "    \"Target Encoding\": prepare_and_evaluate(target_encoding),\n",
    "    \"Hashing Encoding\": prepare_and_evaluate(hashing_encoding),\n",
    "    \"Backward Difference Encoding\": prepare_and_evaluate(backward_difference_encoding),\n",
    "    \"Polynomial Encoding\": prepare_and_evaluate(polynomial_encoding),\n",
    "    \"Helmert Encoding\": prepare_and_evaluate(helmert_encoding),\n",
    "    \"Sum Encoding\": prepare_and_evaluate(sum_encoding),\n",
    "    \"One-Hot Encoding\": prepare_and_evaluate(onehot_encoding_sklearn)\n",
    "\n",
    "}\n",
    "\n",
    "# Flatten the results\n",
    "flattened_results = {}\n",
    "for encoding, models in results.items():\n",
    "    for model, scores in models.items():\n",
    "        for score, value in scores.items():\n",
    "            flattened_results[(encoding, model, score)] = value\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(flattened_results, index=[0])\n",
    "\n",
    "# Transpose the DataFrame for better visualization\n",
    "results_df = results_df.T.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "results_df.columns = ['Encoding', 'Model', 'Score', 'Value']\n",
    "\n",
    "# Pivot the DataFrame to have models as columns and scores as rows for each encoding\n",
    "results_df = results_df.pivot_table(index=['Score', 'Encoding'], columns='Model', values='Value')\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5424e584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>Encoding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Test MAE</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>11913.793600</td>\n",
       "      <td>14151.743678</td>\n",
       "      <td>15572.431890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>12202.661443</td>\n",
       "      <td>14145.097757</td>\n",
       "      <td>15404.203670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>12334.491225</td>\n",
       "      <td>13900.037137</td>\n",
       "      <td>15434.297927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>12542.878922</td>\n",
       "      <td>14164.724294</td>\n",
       "      <td>16136.843099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>12731.425122</td>\n",
       "      <td>14402.230365</td>\n",
       "      <td>14746.890466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>12012.119757</td>\n",
       "      <td>13968.093158</td>\n",
       "      <td>14932.043718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>12191.993787</td>\n",
       "      <td>13979.644723</td>\n",
       "      <td>15395.581683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>12552.084293</td>\n",
       "      <td>14045.058854</td>\n",
       "      <td>15255.252165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>12162.782098</td>\n",
       "      <td>13921.821498</td>\n",
       "      <td>15421.412776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>12561.407724</td>\n",
       "      <td>14062.712825</td>\n",
       "      <td>15264.927628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>11600.022031</td>\n",
       "      <td>13800.968747</td>\n",
       "      <td>15351.633161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Test R2</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>0.940118</td>\n",
       "      <td>0.914890</td>\n",
       "      <td>0.896413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>0.940078</td>\n",
       "      <td>0.913052</td>\n",
       "      <td>0.900251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>0.939426</td>\n",
       "      <td>0.914435</td>\n",
       "      <td>0.900752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>0.936843</td>\n",
       "      <td>0.915118</td>\n",
       "      <td>0.894539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>0.936348</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.910275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>0.940888</td>\n",
       "      <td>0.913356</td>\n",
       "      <td>0.899869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>0.939315</td>\n",
       "      <td>0.914723</td>\n",
       "      <td>0.904329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>0.939668</td>\n",
       "      <td>0.913281</td>\n",
       "      <td>0.901609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>0.938473</td>\n",
       "      <td>0.913846</td>\n",
       "      <td>0.904571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>0.938726</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.899784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>0.942905</td>\n",
       "      <td>0.918318</td>\n",
       "      <td>0.890545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Test RMSE</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>19193.128323</td>\n",
       "      <td>22881.713036</td>\n",
       "      <td>25243.527501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>19199.499482</td>\n",
       "      <td>23127.402392</td>\n",
       "      <td>24771.394451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>19303.671690</td>\n",
       "      <td>22942.716340</td>\n",
       "      <td>24709.152890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>19710.943360</td>\n",
       "      <td>22850.982528</td>\n",
       "      <td>25470.777834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>19788.115186</td>\n",
       "      <td>23498.768834</td>\n",
       "      <td>23493.850470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>19069.233683</td>\n",
       "      <td>23086.942787</td>\n",
       "      <td>24818.830890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>19321.416294</td>\n",
       "      <td>22904.036530</td>\n",
       "      <td>24259.771086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>19265.144337</td>\n",
       "      <td>23096.918382</td>\n",
       "      <td>24602.271677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>19454.945009</td>\n",
       "      <td>23021.631529</td>\n",
       "      <td>24229.042060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>19414.883523</td>\n",
       "      <td>23102.062395</td>\n",
       "      <td>24829.396368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>18741.208374</td>\n",
       "      <td>22416.167762</td>\n",
       "      <td>25948.685229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Train MAE</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>4569.630715</td>\n",
       "      <td>5709.008291</td>\n",
       "      <td>1658.667034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>4534.509535</td>\n",
       "      <td>5669.683064</td>\n",
       "      <td>1484.054754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>5080.344279</td>\n",
       "      <td>5623.591922</td>\n",
       "      <td>1877.053428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>4611.170228</td>\n",
       "      <td>5543.028055</td>\n",
       "      <td>1568.362113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>4957.483488</td>\n",
       "      <td>5874.330223</td>\n",
       "      <td>1875.569142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>4963.153489</td>\n",
       "      <td>5542.385627</td>\n",
       "      <td>1726.794660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>4607.636117</td>\n",
       "      <td>5679.790998</td>\n",
       "      <td>1462.486455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>4997.338919</td>\n",
       "      <td>5660.019387</td>\n",
       "      <td>1769.950144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>4498.581603</td>\n",
       "      <td>5295.487973</td>\n",
       "      <td>1601.744074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>4991.775615</td>\n",
       "      <td>5660.019387</td>\n",
       "      <td>1769.950144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>4482.125734</td>\n",
       "      <td>5508.865667</td>\n",
       "      <td>1567.611583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Train R2</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>0.993712</td>\n",
       "      <td>0.983512</td>\n",
       "      <td>0.999040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>0.993777</td>\n",
       "      <td>0.983623</td>\n",
       "      <td>0.999239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>0.992364</td>\n",
       "      <td>0.983765</td>\n",
       "      <td>0.998806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>0.993520</td>\n",
       "      <td>0.984339</td>\n",
       "      <td>0.999144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.982785</td>\n",
       "      <td>0.998799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>0.992743</td>\n",
       "      <td>0.984997</td>\n",
       "      <td>0.998986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>0.993513</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>0.999259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>0.992589</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.998935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>0.993940</td>\n",
       "      <td>0.985052</td>\n",
       "      <td>0.999114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>0.992576</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.998935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>0.994040</td>\n",
       "      <td>0.984553</td>\n",
       "      <td>0.999146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Train RMSE</th>\n",
       "      <th>Backward Difference Encoding</th>\n",
       "      <td>5874.926661</td>\n",
       "      <td>9513.346031</td>\n",
       "      <td>2295.682845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary Encoding</th>\n",
       "      <td>5844.495283</td>\n",
       "      <td>9481.246075</td>\n",
       "      <td>2044.267997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummified Encoding</th>\n",
       "      <td>6474.158921</td>\n",
       "      <td>9439.947841</td>\n",
       "      <td>2560.570744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency Encoding</th>\n",
       "      <td>5964.086537</td>\n",
       "      <td>9271.636687</td>\n",
       "      <td>2167.144054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Encoding</th>\n",
       "      <td>6329.819329</td>\n",
       "      <td>9720.720641</td>\n",
       "      <td>2567.802190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helmert Encoding</th>\n",
       "      <td>6311.305476</td>\n",
       "      <td>9074.920474</td>\n",
       "      <td>2358.972749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Encoding</th>\n",
       "      <td>5967.037485</td>\n",
       "      <td>9211.055605</td>\n",
       "      <td>2016.945240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot Encoding</th>\n",
       "      <td>6378.236962</td>\n",
       "      <td>9448.406826</td>\n",
       "      <td>2417.372542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Encoding</th>\n",
       "      <td>5767.284460</td>\n",
       "      <td>9058.071716</td>\n",
       "      <td>2205.357358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum Encoding</th>\n",
       "      <td>6383.503008</td>\n",
       "      <td>9448.406826</td>\n",
       "      <td>2417.372542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target Encoding</th>\n",
       "      <td>5719.821910</td>\n",
       "      <td>9208.087328</td>\n",
       "      <td>2164.905898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                                        CatBoost      LightGBM  \\\n",
       "Score      Encoding                                                   \n",
       "Test MAE   Backward Difference Encoding  11913.793600  14151.743678   \n",
       "           Binary Encoding               12202.661443  14145.097757   \n",
       "           Dummified Encoding            12334.491225  13900.037137   \n",
       "           Frequency Encoding            12542.878922  14164.724294   \n",
       "           Hashing Encoding              12731.425122  14402.230365   \n",
       "           Helmert Encoding              12012.119757  13968.093158   \n",
       "           Label Encoding                12191.993787  13979.644723   \n",
       "           One-Hot Encoding              12552.084293  14045.058854   \n",
       "           Polynomial Encoding           12162.782098  13921.821498   \n",
       "           Sum Encoding                  12561.407724  14062.712825   \n",
       "           Target Encoding               11600.022031  13800.968747   \n",
       "Test R2    Backward Difference Encoding      0.940118      0.914890   \n",
       "           Binary Encoding                   0.940078      0.913052   \n",
       "           Dummified Encoding                0.939426      0.914435   \n",
       "           Frequency Encoding                0.936843      0.915118   \n",
       "           Hashing Encoding                  0.936348      0.910237   \n",
       "           Helmert Encoding                  0.940888      0.913356   \n",
       "           Label Encoding                    0.939315      0.914723   \n",
       "           One-Hot Encoding                  0.939668      0.913281   \n",
       "           Polynomial Encoding               0.938473      0.913846   \n",
       "           Sum Encoding                      0.938726      0.913242   \n",
       "           Target Encoding                   0.942905      0.918318   \n",
       "Test RMSE  Backward Difference Encoding  19193.128323  22881.713036   \n",
       "           Binary Encoding               19199.499482  23127.402392   \n",
       "           Dummified Encoding            19303.671690  22942.716340   \n",
       "           Frequency Encoding            19710.943360  22850.982528   \n",
       "           Hashing Encoding              19788.115186  23498.768834   \n",
       "           Helmert Encoding              19069.233683  23086.942787   \n",
       "           Label Encoding                19321.416294  22904.036530   \n",
       "           One-Hot Encoding              19265.144337  23096.918382   \n",
       "           Polynomial Encoding           19454.945009  23021.631529   \n",
       "           Sum Encoding                  19414.883523  23102.062395   \n",
       "           Target Encoding               18741.208374  22416.167762   \n",
       "Train MAE  Backward Difference Encoding   4569.630715   5709.008291   \n",
       "           Binary Encoding                4534.509535   5669.683064   \n",
       "           Dummified Encoding             5080.344279   5623.591922   \n",
       "           Frequency Encoding             4611.170228   5543.028055   \n",
       "           Hashing Encoding               4957.483488   5874.330223   \n",
       "           Helmert Encoding               4963.153489   5542.385627   \n",
       "           Label Encoding                 4607.636117   5679.790998   \n",
       "           One-Hot Encoding               4997.338919   5660.019387   \n",
       "           Polynomial Encoding            4498.581603   5295.487973   \n",
       "           Sum Encoding                   4991.775615   5660.019387   \n",
       "           Target Encoding                4482.125734   5508.865667   \n",
       "Train R2   Backward Difference Encoding      0.993712      0.983512   \n",
       "           Binary Encoding                   0.993777      0.983623   \n",
       "           Dummified Encoding                0.992364      0.983765   \n",
       "           Frequency Encoding                0.993520      0.984339   \n",
       "           Hashing Encoding                  0.992701      0.982785   \n",
       "           Helmert Encoding                  0.992743      0.984997   \n",
       "           Label Encoding                    0.993513      0.984543   \n",
       "           One-Hot Encoding                  0.992589      0.983736   \n",
       "           Polynomial Encoding               0.993940      0.985052   \n",
       "           Sum Encoding                      0.992576      0.983736   \n",
       "           Target Encoding                   0.994040      0.984553   \n",
       "Train RMSE Backward Difference Encoding   5874.926661   9513.346031   \n",
       "           Binary Encoding                5844.495283   9481.246075   \n",
       "           Dummified Encoding             6474.158921   9439.947841   \n",
       "           Frequency Encoding             5964.086537   9271.636687   \n",
       "           Hashing Encoding               6329.819329   9720.720641   \n",
       "           Helmert Encoding               6311.305476   9074.920474   \n",
       "           Label Encoding                 5967.037485   9211.055605   \n",
       "           One-Hot Encoding               6378.236962   9448.406826   \n",
       "           Polynomial Encoding            5767.284460   9058.071716   \n",
       "           Sum Encoding                   6383.503008   9448.406826   \n",
       "           Target Encoding                5719.821910   9208.087328   \n",
       "\n",
       "Model                                         XGBoost  \n",
       "Score      Encoding                                    \n",
       "Test MAE   Backward Difference Encoding  15572.431890  \n",
       "           Binary Encoding               15404.203670  \n",
       "           Dummified Encoding            15434.297927  \n",
       "           Frequency Encoding            16136.843099  \n",
       "           Hashing Encoding              14746.890466  \n",
       "           Helmert Encoding              14932.043718  \n",
       "           Label Encoding                15395.581683  \n",
       "           One-Hot Encoding              15255.252165  \n",
       "           Polynomial Encoding           15421.412776  \n",
       "           Sum Encoding                  15264.927628  \n",
       "           Target Encoding               15351.633161  \n",
       "Test R2    Backward Difference Encoding      0.896413  \n",
       "           Binary Encoding                   0.900251  \n",
       "           Dummified Encoding                0.900752  \n",
       "           Frequency Encoding                0.894539  \n",
       "           Hashing Encoding                  0.910275  \n",
       "           Helmert Encoding                  0.899869  \n",
       "           Label Encoding                    0.904329  \n",
       "           One-Hot Encoding                  0.901609  \n",
       "           Polynomial Encoding               0.904571  \n",
       "           Sum Encoding                      0.899784  \n",
       "           Target Encoding                   0.890545  \n",
       "Test RMSE  Backward Difference Encoding  25243.527501  \n",
       "           Binary Encoding               24771.394451  \n",
       "           Dummified Encoding            24709.152890  \n",
       "           Frequency Encoding            25470.777834  \n",
       "           Hashing Encoding              23493.850470  \n",
       "           Helmert Encoding              24818.830890  \n",
       "           Label Encoding                24259.771086  \n",
       "           One-Hot Encoding              24602.271677  \n",
       "           Polynomial Encoding           24229.042060  \n",
       "           Sum Encoding                  24829.396368  \n",
       "           Target Encoding               25948.685229  \n",
       "Train MAE  Backward Difference Encoding   1658.667034  \n",
       "           Binary Encoding                1484.054754  \n",
       "           Dummified Encoding             1877.053428  \n",
       "           Frequency Encoding             1568.362113  \n",
       "           Hashing Encoding               1875.569142  \n",
       "           Helmert Encoding               1726.794660  \n",
       "           Label Encoding                 1462.486455  \n",
       "           One-Hot Encoding               1769.950144  \n",
       "           Polynomial Encoding            1601.744074  \n",
       "           Sum Encoding                   1769.950144  \n",
       "           Target Encoding                1567.611583  \n",
       "Train R2   Backward Difference Encoding      0.999040  \n",
       "           Binary Encoding                   0.999239  \n",
       "           Dummified Encoding                0.998806  \n",
       "           Frequency Encoding                0.999144  \n",
       "           Hashing Encoding                  0.998799  \n",
       "           Helmert Encoding                  0.998986  \n",
       "           Label Encoding                    0.999259  \n",
       "           One-Hot Encoding                  0.998935  \n",
       "           Polynomial Encoding               0.999114  \n",
       "           Sum Encoding                      0.998935  \n",
       "           Target Encoding                   0.999146  \n",
       "Train RMSE Backward Difference Encoding   2295.682845  \n",
       "           Binary Encoding                2044.267997  \n",
       "           Dummified Encoding             2560.570744  \n",
       "           Frequency Encoding             2167.144054  \n",
       "           Hashing Encoding               2567.802190  \n",
       "           Helmert Encoding               2358.972749  \n",
       "           Label Encoding                 2016.945240  \n",
       "           One-Hot Encoding               2417.372542  \n",
       "           Polynomial Encoding            2205.357358  \n",
       "           Sum Encoding                   2417.372542  \n",
       "           Target Encoding                2164.905898  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71521c",
   "metadata": {},
   "source": [
    "## **3. Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d87b395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "39a640a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>462</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>14</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>129</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>2</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>2571</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>129</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>129</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>129</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>127</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>2055</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>70</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>69</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>71</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>69</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>69</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>14</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>2412</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>1241</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>2483</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing_values data_type\n",
       "LotFrontage              462   float64\n",
       "MasVnrArea                14   float64\n",
       "GarageArea                 1   float64\n",
       "GarageCars                 1   float64\n",
       "BsmtFinSF1                 1   float64\n",
       "GarageYrBlt              129   float64\n",
       "BsmtFinSF2                 1   float64\n",
       "BsmtUnfSF                  1   float64\n",
       "TotalBsmtSF                1   float64\n",
       "BsmtFullBath               2   float64\n",
       "BsmtHalfBath               2   float64\n",
       "PoolQC                  2571    object\n",
       "GarageCond               129    object\n",
       "GarageQual               129    object\n",
       "GarageFinish             129    object\n",
       "GarageType               127    object\n",
       "Electrical                 1    object\n",
       "Fence                   2055    object\n",
       "BsmtFinType2              70    object\n",
       "BsmtFinType1              69    object\n",
       "BsmtExposure              71    object\n",
       "BsmtCond                  69    object\n",
       "BsmtQual                  69    object\n",
       "MasVnrType                14    object\n",
       "Alley                   2412    object\n",
       "FireplaceQu             1241    object\n",
       "MiscFeature             2483    object"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = miss_val.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "missing_values_df = pd.DataFrame(missing_values, columns=['missing_values'])\n",
    "missing_values_df['data_type'] = miss_val[missing_values.index].dtypes\n",
    "\n",
    "missing_values_df.sort_values(by='data_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f079a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lot Frontage: NaN Probably means 0 (0.0)\n",
    "# MasVnrArea:   NaN Probably means 0 (0.0)\n",
    "# GarageArea:   NaN Probably means 0 (0.0)\n",
    "# BsmtFinSF1:   NaN Probably means 0 (0.0)\n",
    "# GarageYrBlt:  NaN Probably means 0 (0000)\n",
    "# BsmtUnfSF:    NaN Probably means 0 (0.0)\n",
    "# TotalBsmtSF:  NaN Probably means 0 (0.0)\n",
    "# BsmtFullBath: NaN Probably means 0 (0.0)\n",
    "# BsmtHalfBath: NaN Probably means 0 (0.0)\n",
    "# PoolQC:       NaN Probably means 'No Pool'. Will Replace with none\n",
    "# GarageCond:   NaN Probably means 'No Garage'. Will Replace with none\n",
    "# GarageQual:   NaN Probably means 'No Garage'. Will Replace with none\n",
    "# GarageFinish: NaN Probably means 'No Garage'. Will Replace with none\n",
    "# GarageType:   NaN Probably means 'No Garage'. Unusual because 2 less.\n",
    "# Fence:        NaN Probably means 'No Fence'.  Will Replace with none\n",
    "# BsmtFinType2: NaN Probably means 'No Bsmt'.   Will Replace with none\n",
    "# BsmtFinType1: NaN Probably means 'No Bsmt'.   Will Replace with none\n",
    "# BsmtExposure: NaN Probably means 'No Bsmt'. Will Replace with none\n",
    "# BsmtCond:     NaN Probably means 'No Bsmt'. Will Replace with none\n",
    "# BsmtQual:     NaN Probably means 'No Bsmt'. Will Replace with none\n",
    "# Alley:        NaN Probably means 'No Alley'. Will Replace with none\n",
    "# FireplaceQu:  NaN Probably means 'No Fireplace'. Will Replace with none\n",
    "# MiscFeature:  NaN Probably means 'No MiscFeature'. Will Replace with none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "05a95aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in miss_val.columns:\n",
    "    if miss_val[col].isnull().sum() > 0:     # are there are missing values?\n",
    "        if miss_val[col].dtype == 'object':  # if the column is of object type fill 'Unk'\n",
    "            miss_val[col].fillna('None', inplace=True)\n",
    "        elif miss_val[col].dtype in ['int64', 'float64']:  # if the column is of numeric type\n",
    "            miss_val[col].fillna(0.0, inplace=True)          # fill with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2ffd81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = miss_val.copy()\n",
    "dummified_encoding = miss_val.copy()\n",
    "ordinal_encoding = miss_val.copy()\n",
    "binary_encoding = miss_val.copy()\n",
    "frequency_encoding = miss_val.copy()\n",
    "hashing_encoding = miss_val.copy()\n",
    "target_encoding = miss_val.copy()\n",
    "backward_difference_encoding = miss_val.copy()\n",
    "polynomial_encoding = miss_val.copy()\n",
    "helmert_encoding = miss_val.copy()\n",
    "sum_encoding = miss_val.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c675920c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/category_encoders/base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Ordinal Encoding\n",
    "# Note: You need to specify the order of categories for each ordinal feature\n",
    "# oe = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "# ordinal_encoding['Quality'] = oe.fit_transform(ordinal_encoding[['Quality']])\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "for col in label_encoding.columns:\n",
    "    if label_encoding[col].dtype == 'object':\n",
    "        label_encoding[col] = le.fit_transform(label_encoding[col])\n",
    "\n",
    "# Dummified\n",
    "dummified_encoding = pd.get_dummies(dummified_encoding)\n",
    "\n",
    "# Binary Encoding\n",
    "be = BinaryEncoder()\n",
    "binary_encoding = be.fit_transform(binary_encoding)\n",
    "\n",
    "# Frequency Encoding\n",
    "for col in frequency_encoding.columns:\n",
    "    if frequency_encoding[col].dtype == 'object':\n",
    "        freq = frequency_encoding[col].value_counts(normalize=True)\n",
    "        frequency_encoding[col] = frequency_encoding[col].map(freq)\n",
    "\n",
    "# Hashing Encoding\n",
    "fh = FeatureHasher(n_features=10, input_type='string')\n",
    "for col in hashing_encoding.columns:\n",
    "    if hashing_encoding[col].dtype == 'object':\n",
    "        hashed_features = fh.transform(hashing_encoding[[col]].astype(str).values)\n",
    "        hashed_features = pd.DataFrame(hashed_features.toarray(), columns=[f\"{col}_{i}\" for i in range(10)])\n",
    "        hashing_encoding = pd.concat([hashing_encoding, hashed_features], axis=1)\n",
    "        hashing_encoding = hashing_encoding.drop(col, axis=1)\n",
    "\n",
    "# Target Encoding with smoothing\n",
    "te = TargetEncoder(smoothing=10)  # adjust the smoothing parameter as needed\n",
    "for col in target_encoding.drop(columns='SalePrice').columns:\n",
    "    if target_encoding[col].dtype == 'object':\n",
    "        target_encoding[col] = te.fit_transform(target_encoding[col], target_encoding['SalePrice'])\n",
    "        \n",
    "# Backward Difference Encoding\n",
    "encoder = ce.BackwardDifferenceEncoder()\n",
    "backward_difference_encoding = encoder.fit_transform(backward_difference_encoding)\n",
    "\n",
    "# Polynomial Encoding\n",
    "encoder = ce.PolynomialEncoder()\n",
    "polynomial_encoding = encoder.fit_transform(polynomial_encoding)\n",
    "\n",
    "# Helmert Encoding\n",
    "encoder = ce.HelmertEncoder()\n",
    "helmert_encoding = encoder.fit_transform(helmert_encoding)\n",
    "\n",
    "# Sum Encoding\n",
    "encoder = ce.SumEncoder()\n",
    "sum_encoding = encoder.fit_transform(sum_encoding)\n",
    "\n",
    "# One-Hot Encoding with sklearn\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "onehot_encoding_sklearn = miss_val.copy()\n",
    "# Select only the object columns\n",
    "object_cols = onehot_encoding_sklearn.select_dtypes(include='object').columns\n",
    "# Fit and transform the object columns\n",
    "onehot_encoded_cols = ohe.fit_transform(onehot_encoding_sklearn[object_cols])\n",
    "# The output of the transformation is a NumPy array, so we need to convert it back to a DataFrame\n",
    "onehot_encoded_cols_df = pd.DataFrame(onehot_encoded_cols, columns=ohe.get_feature_names_out(object_cols))\n",
    "# Drop the original object columns from the original DataFrame\n",
    "onehot_encoding_sklearn = onehot_encoding_sklearn.drop(object_cols, axis=1)\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "onehot_encoding_sklearn = pd.concat([onehot_encoding_sklearn, onehot_encoded_cols_df], axis=1)\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c9a3f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cff6f63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.233e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36184e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.610e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.10535e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.012e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.612e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28629e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.705e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.400e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3618e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.363e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36075e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.116e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.09892e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.396e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.285e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.63291e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.387e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.611e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.54254e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.470e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.86307e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.375e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.484e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.13219e-21): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.610e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.10535e-20): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                                        CatBoost    ElasticNet  \\\n",
      "Score      Encoding                                                   \n",
      "Test MAE   Backward Difference Encoding  12218.896118  16531.138609   \n",
      "           Binary Encoding               12043.356304  17037.633495   \n",
      "           Dummified Encoding            12498.476746  17017.683272   \n",
      "           Frequency Encoding            12255.060993  18733.370265   \n",
      "           Hashing Encoding              12460.727472  17209.649317   \n",
      "           Helmert Encoding              11906.729468  14353.887984   \n",
      "           Label Encoding                12480.852357  17546.398235   \n",
      "           One-Hot Encoding              12498.476746  17017.683272   \n",
      "           Polynomial Encoding           11951.099139  17017.674479   \n",
      "           Sum Encoding                  12559.738165  16857.204493   \n",
      "           Target Encoding               11884.479674  15870.434460   \n",
      "Test R2    Backward Difference Encoding      0.939206      0.889882   \n",
      "           Binary Encoding                   0.939274      0.882198   \n",
      "           Dummified Encoding                0.938065      0.883170   \n",
      "           Frequency Encoding                0.940233      0.863763   \n",
      "           Hashing Encoding                  0.937850      0.880609   \n",
      "           Helmert Encoding                  0.943530      0.915642   \n",
      "           Label Encoding                    0.936552      0.882538   \n",
      "           One-Hot Encoding                  0.938065      0.883170   \n",
      "           Polynomial Encoding               0.940480      0.883170   \n",
      "           Sum Encoding                      0.939582      0.886129   \n",
      "           Target Encoding                   0.939055      0.899442   \n",
      "Test RMSE  Backward Difference Encoding  19338.702611  26027.127057   \n",
      "           Binary Encoding               19327.857311  26919.956740   \n",
      "           Dummified Encoding            19519.376879  26808.662500   \n",
      "           Frequency Encoding            19174.741870  28949.771972   \n",
      "           Hashing Encoding              19553.249272  27100.887670   \n",
      "           Helmert Encoding              18638.336278  22780.389890   \n",
      "           Label Encoding                19756.298600  26881.069455   \n",
      "           One-Hot Encoding              19519.376879  26808.662500   \n",
      "           Polynomial Encoding           19134.954368  26808.643073   \n",
      "           Sum Encoding                  19278.862933  26466.995621   \n",
      "           Target Encoding               19362.732603  24871.673243   \n",
      "Train MAE  Backward Difference Encoding   4526.492211  15483.909487   \n",
      "           Binary Encoding                4465.444983  15962.322763   \n",
      "           Dummified Encoding             5103.205811  15967.177646   \n",
      "           Frequency Encoding             4689.405886  17658.797237   \n",
      "           Hashing Encoding               4882.768173  16345.994776   \n",
      "           Helmert Encoding               4967.825548  13255.386198   \n",
      "           Label Encoding                 4551.185035  16239.564420   \n",
      "           One-Hot Encoding               5103.205811  15967.177646   \n",
      "           Polynomial Encoding            4458.097874  15967.177993   \n",
      "           Sum Encoding                   5070.313238  15732.334495   \n",
      "           Target Encoding                4493.891706  14951.576492   \n",
      "Train R2   Backward Difference Encoding      0.993725      0.891477   \n",
      "           Binary Encoding                   0.994001      0.885214   \n",
      "           Dummified Encoding                0.992252      0.885425   \n",
      "           Frequency Encoding                0.993340      0.865893   \n",
      "           Hashing Encoding                  0.992810      0.881759   \n",
      "           Helmert Encoding                  0.992571      0.919250   \n",
      "           Label Encoding                    0.993819      0.886336   \n",
      "           One-Hot Encoding                  0.992252      0.885425   \n",
      "           Polynomial Encoding               0.994039      0.885425   \n",
      "           Sum Encoding                      0.992281      0.888365   \n",
      "           Target Encoding                   0.993881      0.908064   \n",
      "Train RMSE Backward Difference Encoding   5869.036127  24406.687234   \n",
      "           Binary Encoding                5738.400010  25101.123390   \n",
      "           Dummified Encoding             6521.231904  25077.956055   \n",
      "           Frequency Encoding             6046.361812  27131.447225   \n",
      "           Hashing Encoding               6282.317361  25476.012695   \n",
      "           Helmert Encoding               6385.562174  21053.212047   \n",
      "           Label Encoding                 5824.518937  24978.114285   \n",
      "           One-Hot Encoding               6521.231904  25077.956055   \n",
      "           Polynomial Encoding            5719.921749  25077.966361   \n",
      "           Sum Encoding                   6509.090125  24754.131427   \n",
      "           Target Encoding                5795.417355  22464.232789   \n",
      "\n",
      "Model                                           Lasso      LightGBM  \\\n",
      "Score      Encoding                                                   \n",
      "Test MAE   Backward Difference Encoding  14566.324966  13765.266999   \n",
      "           Binary Encoding               14836.912358  14598.243244   \n",
      "           Dummified Encoding            14561.275294  14061.070261   \n",
      "           Frequency Encoding            16854.406396  14395.045526   \n",
      "           Hashing Encoding              15538.143613  14394.638275   \n",
      "           Helmert Encoding              14567.227741  13907.235634   \n",
      "           Label Encoding                17369.586881  13938.785498   \n",
      "           One-Hot Encoding              14561.275294  14061.070261   \n",
      "           Polynomial Encoding           14698.857901  13689.073503   \n",
      "           Sum Encoding                  15366.226729  14044.800243   \n",
      "           Target Encoding               15677.508821  13501.855344   \n",
      "Test R2    Backward Difference Encoding      0.914750      0.916099   \n",
      "           Binary Encoding                   0.911475      0.909780   \n",
      "           Dummified Encoding                0.914230      0.913656   \n",
      "           Frequency Encoding                0.892177      0.912088   \n",
      "           Hashing Encoding                  0.904759      0.910417   \n",
      "           Helmert Encoding                  0.913907      0.913707   \n",
      "           Label Encoding                    0.891149      0.917721   \n",
      "           One-Hot Encoding                  0.914230      0.913656   \n",
      "           Polynomial Encoding               0.912761      0.916937   \n",
      "           Sum Encoding                      0.894974      0.913702   \n",
      "           Target Encoding                   0.902177      0.921071   \n",
      "Test RMSE  Backward Difference Encoding  22900.425031  22718.497022   \n",
      "           Binary Encoding               23336.247756  23558.505647   \n",
      "           Dummified Encoding            22970.194107  23046.915446   \n",
      "           Frequency Encoding            25754.493382  23255.288222   \n",
      "           Hashing Encoding              24205.206364  23475.220904   \n",
      "           Helmert Encoding              23013.419264  23040.097235   \n",
      "           Label Encoding                25876.949621  22497.898269   \n",
      "           One-Hot Encoding              22970.194107  23046.915446   \n",
      "           Polynomial Encoding           23166.117468  22604.848894   \n",
      "           Sum Encoding                  25418.198433  23040.859872   \n",
      "           Target Encoding               24531.187298  22035.152260   \n",
      "Train MAE  Backward Difference Encoding  12063.485157   5753.712248   \n",
      "           Binary Encoding               13106.724431   5670.200661   \n",
      "           Dummified Encoding            12058.104129   5742.481022   \n",
      "           Frequency Encoding            15279.657113   5652.834342   \n",
      "           Hashing Encoding              13526.910931   5862.829373   \n",
      "           Helmert Encoding              12051.044580   5549.900349   \n",
      "           Label Encoding                15841.449510   5668.975898   \n",
      "           One-Hot Encoding              12058.104129   5742.481022   \n",
      "           Polynomial Encoding           12064.252466   5311.154561   \n",
      "           Sum Encoding                  12056.005124   5742.481022   \n",
      "           Target Encoding               14763.551690   5593.049573   \n",
      "Train R2   Backward Difference Encoding      0.941191      0.983712   \n",
      "           Binary Encoding                   0.929665      0.983377   \n",
      "           Dummified Encoding                0.941229      0.983591   \n",
      "           Frequency Encoding                0.903414      0.983196   \n",
      "           Hashing Encoding                  0.927967      0.982813   \n",
      "           Helmert Encoding                  0.941263      0.984650   \n",
      "           Label Encoding                    0.895959      0.983761   \n",
      "           One-Hot Encoding                  0.941229      0.983591   \n",
      "           Polynomial Encoding               0.941218      0.984606   \n",
      "           Sum Encoding                      0.941239      0.983591   \n",
      "           Target Encoding                   0.911088      0.984163   \n",
      "Train RMSE Backward Difference Encoding  17966.691780   9455.516159   \n",
      "           Binary Encoding               19648.653444   9552.145508   \n",
      "           Dummified Encoding            17960.911837   9490.623047   \n",
      "           Frequency Encoding            23025.244055   9603.981778   \n",
      "           Hashing Encoding              19884.466977   9712.745281   \n",
      "           Helmert Encoding              17955.747239   9179.219009   \n",
      "           Label Encoding                23897.374488   9441.132164   \n",
      "           One-Hot Encoding              17960.911837   9490.623047   \n",
      "           Polynomial Encoding           17962.563969   9192.397629   \n",
      "           Sum Encoding                  17959.364886   9490.623047   \n",
      "           Target Encoding               22091.613613   9323.512018   \n",
      "\n",
      "Model                                    RandomForest         Ridge  \\\n",
      "Score      Encoding                                                   \n",
      "Test MAE   Backward Difference Encoding  15778.332849  14421.139232   \n",
      "           Binary Encoding               15693.593488  14662.083056   \n",
      "           Dummified Encoding            15872.457171  14400.922417   \n",
      "           Frequency Encoding            16024.173876  16837.718032   \n",
      "           Hashing Encoding              15959.755911  15415.186383   \n",
      "           Helmert Encoding              15814.023915  14502.035919   \n",
      "           Label Encoding                15999.167771  17373.584994   \n",
      "           One-Hot Encoding              15904.078081  14400.922417   \n",
      "           Polynomial Encoding           15692.825504  14400.922417   \n",
      "           Sum Encoding                  16036.705736  14407.307078   \n",
      "           Target Encoding               15399.868837  15675.405039   \n",
      "Test R2    Backward Difference Encoding      0.896652      0.920613   \n",
      "           Binary Encoding                   0.896209      0.914460   \n",
      "           Dummified Encoding                0.892213      0.919058   \n",
      "           Frequency Encoding                0.895073      0.892567   \n",
      "           Hashing Encoding                  0.897019      0.909523   \n",
      "           Helmert Encoding                  0.892603      0.916863   \n",
      "           Label Encoding                    0.891838      0.891120   \n",
      "           One-Hot Encoding                  0.891880      0.919058   \n",
      "           Polynomial Encoding               0.893005      0.919058   \n",
      "           Sum Encoding                      0.895108      0.918940   \n",
      "           Target Encoding                   0.900956      0.902195   \n",
      "Test RMSE  Backward Difference Encoding  25214.419853  22098.916015   \n",
      "           Binary Encoding               25268.319777  22939.449661   \n",
      "           Dummified Encoding            25750.228674  22314.306584   \n",
      "           Frequency Encoding            25406.257593  25707.884433   \n",
      "           Hashing Encoding              25169.599976  23592.033973   \n",
      "           Helmert Encoding              25703.588320  22614.855256   \n",
      "           Label Encoding                25794.922692  25880.371252   \n",
      "           One-Hot Encoding              25789.937216  22314.306584   \n",
      "           Polynomial Encoding           25655.462716  22314.306584   \n",
      "           Sum Encoding                  25402.006945  22330.576695   \n",
      "           Target Encoding               24683.723064  24528.934394   \n",
      "Train MAE  Backward Difference Encoding   5483.132301  12250.433473   \n",
      "           Binary Encoding                5623.114816  13093.345043   \n",
      "           Dummified Encoding             5578.451119  12205.454314   \n",
      "           Frequency Encoding             5558.816570  15264.007760   \n",
      "           Hashing Encoding               5625.172204  13597.339860   \n",
      "           Helmert Encoding               5464.321788  12074.248785   \n",
      "           Label Encoding                 5596.277597  15840.314776   \n",
      "           One-Hot Encoding               5502.471967  12205.454314   \n",
      "           Polynomial Encoding            5449.178406  12205.454314   \n",
      "           Sum Encoding                   5491.023023  12162.883035   \n",
      "           Target Encoding                5501.301274  14763.626801   \n",
      "Train R2   Backward Difference Encoding      0.984716      0.937952   \n",
      "           Binary Encoding                   0.982968      0.928738   \n",
      "           Dummified Encoding                0.984428      0.939495   \n",
      "           Frequency Encoding                0.983783      0.902764   \n",
      "           Hashing Encoding                  0.983038      0.926545   \n",
      "           Helmert Encoding                  0.984557      0.940957   \n",
      "           Label Encoding                    0.983726      0.895956   \n",
      "           One-Hot Encoding                  0.982784      0.939495   \n",
      "           Polynomial Encoding               0.985410      0.939495   \n",
      "           Sum Encoding                      0.983723      0.939746   \n",
      "           Target Encoding                   0.984045      0.911088   \n",
      "Train RMSE Backward Difference Encoding   9159.506581  18454.941985   \n",
      "           Binary Encoding                9668.874625  19777.719158   \n",
      "           Dummified Encoding             9245.399875  18223.939926   \n",
      "           Frequency Encoding             9434.768195  23102.647046   \n",
      "           Hashing Encoding               9649.193009  20079.744285   \n",
      "           Helmert Encoding               9207.025788  18002.446406   \n",
      "           Label Encoding                 9451.472909  23897.718887   \n",
      "           One-Hot Encoding               9721.119551  18223.939926   \n",
      "           Polynomial Encoding            8949.059463  18223.939926   \n",
      "           Sum Encoding                   9452.134068  18186.207596   \n",
      "           Target Encoding                9358.347931  22091.644848   \n",
      "\n",
      "Model                                             SVR       XGBoost  \n",
      "Score      Encoding                                                  \n",
      "Test MAE   Backward Difference Encoding  55020.104367  15693.048056  \n",
      "           Binary Encoding               55020.095872  15159.746018  \n",
      "           Dummified Encoding            55020.106276  14893.925986  \n",
      "           Frequency Encoding            55020.070424  15160.441944  \n",
      "           Hashing Encoding              55020.110345  14434.316179  \n",
      "           Helmert Encoding              55020.104367  15238.926902  \n",
      "           Label Encoding                55020.070424  14718.358641  \n",
      "           One-Hot Encoding              55020.106276  14893.925986  \n",
      "           Polynomial Encoding           55020.104367  15119.051432  \n",
      "           Sum Encoding                  55020.104367  14937.596930  \n",
      "           Target Encoding               55020.069349  14698.310267  \n",
      "Test R2    Backward Difference Encoding     -0.093223      0.901115  \n",
      "           Binary Encoding                  -0.093223      0.901118  \n",
      "           Dummified Encoding               -0.093223      0.910004  \n",
      "           Frequency Encoding               -0.093224      0.897618  \n",
      "           Hashing Encoding                 -0.093223      0.918643  \n",
      "           Helmert Encoding                 -0.093223      0.902856  \n",
      "           Label Encoding                   -0.093224      0.910036  \n",
      "           One-Hot Encoding                 -0.093223      0.910004  \n",
      "           Polynomial Encoding              -0.093223      0.909461  \n",
      "           Sum Encoding                     -0.093223      0.908067  \n",
      "           Target Encoding                  -0.093224      0.899377  \n",
      "Test RMSE  Backward Difference Encoding  82007.101070  24663.871652  \n",
      "           Binary Encoding               82007.112196  24663.529700  \n",
      "           Dummified Encoding            82007.098570  23529.240024  \n",
      "           Frequency Encoding            82007.145525  25096.196419  \n",
      "           Hashing Encoding              82007.093242  22371.467745  \n",
      "           Helmert Encoding              82007.101070  24445.828540  \n",
      "           Label Encoding                82007.145525  23525.068721  \n",
      "           One-Hot Encoding              82007.098570  23529.240024  \n",
      "           Polynomial Encoding           82007.101070  23600.206238  \n",
      "           Sum Encoding                  82007.101070  23781.181701  \n",
      "           Target Encoding               82007.146821  24879.774518  \n",
      "Train MAE  Backward Difference Encoding  52061.937006   1599.172140  \n",
      "           Binary Encoding               52061.919846   1501.455452  \n",
      "           Dummified Encoding            52061.940863   1924.364199  \n",
      "           Frequency Encoding            52061.868442   1713.163888  \n",
      "           Hashing Encoding              52061.949082   1828.299959  \n",
      "           Helmert Encoding              52061.937006   1830.123869  \n",
      "           Label Encoding                52061.868442   1584.392156  \n",
      "           One-Hot Encoding              52061.940863   1924.364199  \n",
      "           Polynomial Encoding           52061.937006   1467.765503  \n",
      "           Sum Encoding                  52061.937006   1924.364199  \n",
      "           Target Encoding               52061.866316   1682.989965  \n",
      "Train R2   Backward Difference Encoding     -0.057984      0.999123  \n",
      "           Binary Encoding                  -0.057984      0.999213  \n",
      "           Dummified Encoding               -0.057984      0.998749  \n",
      "           Frequency Encoding               -0.057984      0.998983  \n",
      "           Hashing Encoding                 -0.057984      0.998815  \n",
      "           Helmert Encoding                 -0.057984      0.998863  \n",
      "           Label Encoding                   -0.057984      0.999096  \n",
      "           One-Hot Encoding                 -0.057984      0.998749  \n",
      "           Polynomial Encoding              -0.057984      0.999249  \n",
      "           Sum Encoding                     -0.057984      0.998749  \n",
      "           Target Encoding                  -0.057984      0.999015  \n",
      "Train RMSE Backward Difference Encoding  76205.671785   2193.964793  \n",
      "           Binary Encoding               76205.670779   2078.991914  \n",
      "           Dummified Encoding            76205.672012   2620.365809  \n",
      "           Frequency Encoding            76205.667769   2362.448240  \n",
      "           Hashing Encoding              76205.672494   2550.027715  \n",
      "           Helmert Encoding              76205.671785   2498.260164  \n",
      "           Label Encoding                76205.667769   2228.097051  \n",
      "           One-Hot Encoding              76205.672012   2620.365809  \n",
      "           Polynomial Encoding           76205.671785   2030.405084  \n",
      "           Sum Encoding                  76205.671785   2620.365809  \n",
      "           Target Encoding               76205.667593   2325.278701  \n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": make_pipeline(ElasticNet()),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"SVR\": make_pipeline(SVR()),\n",
    "    \"RandomForest\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    return {\n",
    "        \"Train R2\": r2_score(y_train, train_predictions),\n",
    "        \"Test R2\": r2_score(y_test, test_predictions),\n",
    "        \"Train RMSE\": sqrt(mean_squared_error(y_train, train_predictions)),\n",
    "        \"Test RMSE\": sqrt(mean_squared_error(y_test, test_predictions)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, train_predictions),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, test_predictions)\n",
    "    }\n",
    "\n",
    "# Define a function to prepare data and evaluate models\n",
    "def prepare_and_evaluate(data):\n",
    "    X = data.drop(columns='SalePrice')\n",
    "    y = data['SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return {name: evaluate_model(model, X_train, X_test, y_train, y_test) for name, model in models.items()}\n",
    "\n",
    "# Prepare data and evaluate models\n",
    "results = {\n",
    "    \"Label Encoding\": prepare_and_evaluate(label_encoding),\n",
    "    \"Dummified Encoding\": prepare_and_evaluate(dummified_encoding),\n",
    "    \"Binary Encoding\": prepare_and_evaluate(binary_encoding),\n",
    "    \"Frequency Encoding\": prepare_and_evaluate(frequency_encoding),\n",
    "    \"Target Encoding\": prepare_and_evaluate(target_encoding),\n",
    "    \"Hashing Encoding\": prepare_and_evaluate(hashing_encoding),\n",
    "    \"Backward Difference Encoding\": prepare_and_evaluate(backward_difference_encoding),\n",
    "    \"Polynomial Encoding\": prepare_and_evaluate(polynomial_encoding),\n",
    "    \"Helmert Encoding\": prepare_and_evaluate(helmert_encoding),\n",
    "    \"Sum Encoding\": prepare_and_evaluate(sum_encoding),\n",
    "    \"One-Hot Encoding\": prepare_and_evaluate(onehot_encoding_sklearn)\n",
    "\n",
    "}\n",
    "\n",
    "# Flatten the results\n",
    "flattened_results = {}\n",
    "for encoding, models in results.items():\n",
    "    for model, scores in models.items():\n",
    "        for score, value in scores.items():\n",
    "            flattened_results[(encoding, model, score)] = value\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(flattened_results, index=[0])\n",
    "\n",
    "# Transpose the DataFrame for better visualization\n",
    "results_df = results_df.T.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "results_df.columns = ['Encoding', 'Model', 'Score', 'Value']\n",
    "\n",
    "# Pivot the DataFrame to have models as columns and scores as rows for each encoding\n",
    "results_df = results_df.pivot_table(index=['Score', 'Encoding'], columns='Model', values='Value')\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654a7cf",
   "metadata": {},
   "source": [
    "**Encoding Models Based on Column Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c036b080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Variable  Ordinal  Nominal  Encoding\n",
      "0      MSSubClass        0        0         0\n",
      "1        BldgType        0        1         0\n",
      "2      HouseStyle        0        1         0\n",
      "3       YearBuilt        0        0         0\n",
      "4    YearRemodAdd        0        0         0\n",
      "5     OverallQual        1        0         0\n",
      "6       ExterQual        1        0         0\n",
      "7       HeatingQC        1        0         0\n",
      "8    BsmtFinType1        1        0         0\n",
      "9    BsmtFinType2        1        0         0\n",
      "10    KitchenQual        1        0         0\n",
      "11    FireplaceQu        1        0         0\n",
      "12     GarageQual        1        0         0\n",
      "13    OverallCond        1        0         0\n",
      "14      ExterCond        1        0         0\n",
      "15       BsmtCond        1        0         0\n",
      "16     Functional        1        0         0\n",
      "17     GarageCond        1        0         0\n",
      "18   Lot Frontage        0        0         0\n",
      "19       Lot Area        0        0         0\n",
      "20       LotShape        0        0         0\n",
      "21    LandContour        0        1         0\n",
      "22      LandSlope        0        0         0\n",
      "23      LotConfig        0        1         0\n",
      "24     Condition1        0        1         0\n",
      "25     Condition2        0        1         0\n",
      "26      RoofStyle        0        1         0\n",
      "27       RoofMatl        0        1         0\n",
      "28    Exterior1st        0        1         0\n",
      "29    Exterior2nd        0        1         0\n",
      "30     MasVnrType        0        1         0\n",
      "31     Foundation        0        1         0\n",
      "32   BsmtExposure        0        0         0\n",
      "33       BsmtQual        1        0         0\n",
      "34     Fireplaces        0        0         0\n",
      "35     MasVnrArea        0        0         0\n",
      "36     BsmtFinSF1        0        0         0\n",
      "37     BsmtFinSF2        0        0         0\n",
      "38      BsmtUnfSF        0        0         0\n",
      "39    TotalBsmtSF        0        0         0\n",
      "40       1stFlrSF        0        0         0\n",
      "41       2ndFlrSF        0        0         0\n",
      "42   LowQualFinSF        0        0         0\n",
      "43      GrLivArea        0        0         0\n",
      "44     GarageArea        0        0         0\n",
      "45   BsmtFullBath        0        0         0\n",
      "46   BsmtHalfBath        0        0         0\n",
      "47       FullBath        0        0         0\n",
      "48       HalfBath        0        0         0\n",
      "49        Bedroom        0        0         0\n",
      "50        Kitchen        0        0         0\n",
      "51   TotRmsAbvGrd        0        0         0\n",
      "52   BsmtFullBath        0        0         0\n",
      "53     GarageType        0        1         0\n",
      "54    GarageYrBlt        0        0         0\n",
      "55   GarageFinish        1        0         0\n",
      "56     GarageCars        0        0         0\n",
      "57     PavedDrive        0        1         0\n",
      "58     WoodDeckSF        0        0         0\n",
      "59    OpenPorchSF        0        0         0\n",
      "60  EnclosedPorch        0        0         0\n",
      "61      3SsnPorch        0        0         0\n",
      "62    ScreenPorch        0        0         0\n",
      "63       PoolArea        0        0         0\n",
      "64         PoolQC        1        0         0\n",
      "65          Fence        0        1         0\n",
      "66    MiscFeature        0        1         0\n",
      "67        MiscVal        0        0         0\n",
      "68       MSZoning        0        1         0\n",
      "69         Street        0        1         0\n",
      "70          Alley        0        1         0\n",
      "71   Neighborhood        0        1         0\n",
      "72      Utilities        0        1         0\n",
      "73        Heating        0        1         0\n",
      "74     CentralAir        0        1         0\n",
      "75     Electrical        0        1         0\n",
      "76         MoSold        0        0         0\n",
      "77         YrSold        0        0         0\n",
      "78       SaleType        0        1         0\n",
      "79  SaleCondition        0        1         0\n"
     ]
    }
   ],
   "source": [
    "# List of variables\n",
    "variables = ['MSSubClass', 'BldgType', 'HouseStyle', 'YearBuilt', 'YearRemodAdd', 'OverallQual', 'ExterQual', \n",
    "             'HeatingQC', 'BsmtFinType1', 'BsmtFinType2', 'KitchenQual', 'FireplaceQu', 'GarageQual', \n",
    "             'OverallCond', 'ExterCond', 'BsmtCond', 'Functional', 'GarageCond', 'Lot Frontage', 'Lot Area', \n",
    "             'LotShape', 'LandContour', 'LandSlope', 'LotConfig', 'Condition1', 'Condition2', 'RoofStyle', \n",
    "             'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'BsmtQual', \n",
    "             'Fireplaces', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', \n",
    "             '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', \n",
    "             'HalfBath', 'Bedroom', 'Kitchen', 'TotRmsAbvGrd', 'BsmtFullBath', 'GarageType', 'GarageYrBlt', \n",
    "             'GarageFinish', 'GarageCars', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', \n",
    "             'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MSZoning', 'Street', 'Alley', \n",
    "             'Neighborhood', 'Utilities', 'Heating', 'CentralAir', 'Electrical', 'MoSold', 'YrSold', 'SaleType', \n",
    "             'SaleCondition']\n",
    "\n",
    "# Define which variables are ordinal, nominal, and encoding\n",
    "ordinal = ['OverallQual', 'ExterQual', 'HeatingQC', 'BsmtFinType1', 'BsmtFinType2', 'KitchenQual', 'FireplaceQu', 'GarageQual', \n",
    "           'OverallCond', 'ExterCond', 'BsmtCond', 'Functional', 'GarageCond', 'BsmtQual', 'GarageFinish', 'PoolQC']\n",
    "nominal = ['MSZoning', 'Street', 'Alley', 'LandContour', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', \n",
    "           'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', \n",
    "           'Heating', 'CentralAir', 'Electrical', 'GarageType', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "# encoding = [.....] # insert your list of variables that need encoding\n",
    "\n",
    "# Create a dictionary\n",
    "data = {'Variable': variables,\n",
    "        'Ordinal': [1 if var in ordinal else 0 for var in variables],\n",
    "        'Nominal': [1 if var in nominal else 0 for var in variables],\n",
    "        'Encoding': [1 if var in encoding else 0 for var in variables]}\n",
    "\n",
    "# Create DataFrame\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5f924",
   "metadata": {},
   "source": [
    "## **scalling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094e1a8",
   "metadata": {},
   "source": [
    "**handling infinites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c745362b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Backward Difference Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Binary Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.905e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n",
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Dummified Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.816e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.397e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Frequency Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.052e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.331e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n",
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Hashing Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.005e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.636e+09, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.586e+09, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.496e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.788e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Helmert Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.671e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.255e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.635e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Label Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.814e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.736e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.088e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.799e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n",
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with One-Hot Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.816e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.397e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Polynomial Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.394e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.284e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with Sum Encoding...\n",
      "Applying StandardScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.102e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.284e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.818e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:3260: RuntimeWarning: overflow encountered in power\n",
      "  out[~pos] = -(np.power(-x[~pos] + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.522e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Input X contains infinity or a value too large for dtype('float64').. Skipping this scaler...\n",
      "Evaluating models with Target Encoding...\n",
      "Applying StandardScaler scaler...\n",
      "Applying RobustScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MinMaxScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying MaxAbsScaler scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e+10, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying QuantileTransformer scaler...\n",
      "Applying PowerTransformer scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:3256: RuntimeWarning: overflow encountered in power\n",
      "  out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                              Lasso  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9412604950511884, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9411914887244605, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9411673346149989, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.941148544508279, 'Test R2': 0.9...   \n",
      "                             QuantileTransformer  {'Train R2': 0.9206160283087647, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9312726044257817, 'Test R2': 0....   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9296771691558913, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9296650546877999, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9296582431084308, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9296318916151882, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9035810411723895, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9164738562071785, 'Test R2': 0....   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9412659290035618, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9412292572311868, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9412041788350571, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9411450493411934, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9206501126775426, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9312793119854473, 'Test R2': 0....   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9034160692735291, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9034153347893209, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9034121491136118, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9032910468752098, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.8448238306141371, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8772925927509173, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9279964923247508, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9279665945312139, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9279514480501312, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9279230730520923, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9037468530901681, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9141094782435805, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9412660498105008, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9412628453224576, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9411899812693382, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9411576350343395, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.920620314193622, 'Test R2': 0.8...   \n",
      "                             PowerTransformer     {'Train R2': 0.93127362089866, 'Test R2': 0.90...   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.895959173338611, 'Test R2': 0.8...   \n",
      "                             RobustScaler         {'Train R2': 0.895958890027206, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.8959568080177909, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.895808815532143, 'Test R2': 0.8...   \n",
      "                             QuantileTransformer  {'Train R2': 0.8404414845643903, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8711385494052906, 'Test R2': 0....   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9412659290035618, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9412292572311868, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9412041788350571, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9411450493411934, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9206501126775426, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9312793119854473, 'Test R2': 0....   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9412645266113713, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9412346748074184, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9411985322866422, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9411784449403526, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.919963255512246, 'Test R2': 0.8...   \n",
      "                             PowerTransformer     {'Train R2': 0.9312411654690862, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9412656036821465, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9412394015986787, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9411433165417095, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9411586204014193, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9206251725363435, 'Test R2': 0....   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.9110881859226607, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9110881429400207, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9110853141734836, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9110318929316602, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.8472132735585836, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.862378213346391, 'Test R2': 0.8...   \n",
      "\n",
      "                                                                                         ElasticNet  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9129806337771895, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8720721099664992, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.6760224091744997, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.7186257006001066, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7502828685333874, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.898462188805951, 'Test R2': 0.8...   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9074148288154233, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8628051453005767, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.6716529168206731, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.6633593531875817, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7385237856912243, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8895843705848262, 'Test R2': 0....   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9227685079107663, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.864796860567195, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.6851783521074024, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.6779767755423072, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7454013532846391, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9102354894962228, 'Test R2': 0....   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.885067332733279, 'Test R2': 0.8...   \n",
      "                             RobustScaler         {'Train R2': 0.8632129070816656, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.5530298818940025, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.5164347254034515, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.6944904014749156, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8556822808721526, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9084185325261602, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.860212716875154, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.6542941309977631, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.6654622147562436, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7268298486112721, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8901892738020385, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9212464895013092, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9034251714066346, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.649857570440072, 'Test R2': 0.6...   \n",
      "                             MaxAbsScaler         {'Train R2': 0.7052960108577506, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7469425903057806, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9000009589416705, 'Test R2': 0....   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.8817154008357593, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8646362923182405, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.5478283275101151, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.5214660593776886, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.6896282227344093, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8508098277863151, 'Test R2': 0....   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9227685079107663, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.864796860567195, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.6851783521074024, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.6779767755423072, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7454013532846391, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9102354894962228, 'Test R2': 0....   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9172095623287171, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8869875282255508, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.6812829971194797, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.7584864471282106, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.7409905083005197, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8992685946646124, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9202809089126985, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8687667598002728, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.5909483446218109, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.6915336633149807, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.715473764580914, 'Test R2': 0.6...   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.8971430510711778, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.8876401571474203, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.6065388364948489, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.442949997490637, 'Test R2': 0.4...   \n",
      "                             QuantileTransformer  {'Train R2': 0.6956745533908999, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8403850988751352, 'Test R2': 0....   \n",
      "\n",
      "                                                                                              Ridge  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.941237695599957, 'Test R2': 0.9...   \n",
      "                             RobustScaler         {'Train R2': 0.9379492369431593, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9372035873189541, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9369685930451689, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.918377878843987, 'Test R2': 0.8...   \n",
      "                             PowerTransformer     {'Train R2': 0.9312447779678219, 'Test R2': 0....   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9296776394170789, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9287375011749056, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9279781867751546, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.92549612854717, 'Test R2': 0.91...   \n",
      "                             QuantileTransformer  {'Train R2': 0.9031155595764456, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9164683144312589, 'Test R2': 0....   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9412644035847275, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9394925298641837, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9387537980957691, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9373350241727723, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9194422825655574, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.931276021652914, 'Test R2': 0.9...   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9034158749166981, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9029299143775702, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9019177363941348, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.8987428430080953, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.8446999160120064, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.8772909278927316, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.927999977639003, 'Test R2': 0.9...   \n",
      "                             RobustScaler         {'Train R2': 0.926541423535253, 'Test R2': 0.9...   \n",
      "                             MinMaxScaler         {'Train R2': 0.9257241358349865, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9242764153254588, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9025020777233059, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9141052792299573, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9412636180016503, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.940952408114087, 'Test R2': 0.9...   \n",
      "                             MinMaxScaler         {'Train R2': 0.9378898736830057, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9378725726910948, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.918476563436112, 'Test R2': 0.8...   \n",
      "                             PowerTransformer     {'Train R2': 0.9312526999633937, 'Test R2': 0....   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.895959090158911, 'Test R2': 0.8...   \n",
      "                             RobustScaler         {'Train R2': 0.895955717695991, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.8953564179754236, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.8931209316202096, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.8403747656666547, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.871137349804282, 'Test R2': 0.8...   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9412644035847275, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9394925298641837, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9387537980957691, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9373350241727723, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9194422825655574, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.931276021652914, 'Test R2': 0.9...   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9412594078358592, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9397529178299853, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9389034496888025, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9386344945165702, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9175798194113783, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9312089327397088, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9412618015812853, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9397424858102267, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9381163348519466, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9375822098184788, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9185711994074678, 'Test R2': 0....   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.9110881199227338, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9110875628146115, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9105404208122586, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9075107638904009, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.8470402757571532, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.86237694262193, 'Test R2': 0.85...   \n",
      "\n",
      "                                                                                                SVR  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': -0.05699951095786959, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.05798505352723038, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056726731007158415, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.056930738629562994, 'Test R2':...   \n",
      "                             QuantileTransformer  {'Train R2': -0.056471075054398856, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.05692773213630242, 'Test R2': ...   \n",
      "Binary Encoding              StandardScaler       {'Train R2': -0.05673440526992657, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.05798499412969216, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056281186888681, 'Test R2': -0...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05629490342770849, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.056087390929911995, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.05666063082804462, 'Test R2': ...   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': -0.05702808023955219, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.057984982320808065, 'Test R2':...   \n",
      "                             MinMaxScaler         {'Train R2': -0.05636559462641921, 'Test R2': ...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05640495672009793, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.05614239211473948, 'Test R2': ...   \n",
      "                             PowerTransformer     {'Train R2': -0.05697761096878606, 'Test R2': ...   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': -0.056589209179593425, 'Test R2':...   \n",
      "                             RobustScaler         {'Train R2': -0.057984421704913025, 'Test R2':...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056617709596274324, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05677948078950035, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.05569006386330444, 'Test R2': ...   \n",
      "                             PowerTransformer     {'Train R2': -0.05631620657658987, 'Test R2': ...   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': -0.056972270384241464, 'Test R2':...   \n",
      "                             RobustScaler         {'Train R2': -0.057985024740881075, 'Test R2':...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056779668504602476, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05622179957019435, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.05648756437979663, 'Test R2': ...   \n",
      "                             PowerTransformer     {'Train R2': -0.056909405940308355, 'Test R2':...   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': -0.05706675440490283, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.05798379800401521, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056426505052267206, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.056214639494495566, 'Test R2':...   \n",
      "                             QuantileTransformer  {'Train R2': -0.056429782599205724, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.056923927182885414, 'Test R2':...   \n",
      "Label Encoding               StandardScaler       {'Train R2': -0.05652766968545908, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.0579850499773209, 'Test R2': -...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056252817479342854, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05638976912495974, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.055644645716651286, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.05634274521808336, 'Test R2': ...   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': -0.05702808023955219, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.057984982320808065, 'Test R2':...   \n",
      "                             MinMaxScaler         {'Train R2': -0.05636559462641921, 'Test R2': ...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.05640495672009793, 'Test R2': ...   \n",
      "                             QuantileTransformer  {'Train R2': -0.05614239211473948, 'Test R2': ...   \n",
      "                             PowerTransformer     {'Train R2': -0.05697761096878606, 'Test R2': ...   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': -0.05688712795521855, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.05798429822674067, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.056429201786167615, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.056429297337572404, 'Test R2':...   \n",
      "                             QuantileTransformer  {'Train R2': -0.056305266333476434, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.0568135526104927, 'Test R2': -...   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': -0.057011177831105986, 'Test R2':...   \n",
      "                             RobustScaler         {'Train R2': -0.05798497250535983, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.05686390219250281, 'Test R2': ...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.056545541974673874, 'Test R2':...   \n",
      "                             QuantileTransformer  {'Train R2': -0.05610102413445284, 'Test R2': ...   \n",
      "Target Encoding              StandardScaler       {'Train R2': -0.05627409063368449, 'Test R2': ...   \n",
      "                             RobustScaler         {'Train R2': -0.05731976301714092, 'Test R2': ...   \n",
      "                             MinMaxScaler         {'Train R2': -0.055720807794355176, 'Test R2':...   \n",
      "                             MaxAbsScaler         {'Train R2': -0.056669306017637755, 'Test R2':...   \n",
      "                             QuantileTransformer  {'Train R2': -0.055185187590555795, 'Test R2':...   \n",
      "                             PowerTransformer     {'Train R2': -0.05563916686714898, 'Test R2': ...   \n",
      "\n",
      "                                                                                       RandomForest  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9847342370492392, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9840400066524645, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9840356761695447, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9845653400004094, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9847041676870889, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9841765404038859, 'Test R2': 0....   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9850869403231564, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9829449114989492, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9838267544071475, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.985052760316812, 'Test R2': 0.8...   \n",
      "                             QuantileTransformer  {'Train R2': 0.9846315396134384, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9839580398330919, 'Test R2': 0....   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9844312067187303, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9839169810075312, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9841421048613304, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9835450701721141, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9846058348460177, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9840238260033057, 'Test R2': 0....   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9839417406787605, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9829420569209489, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9838586088986758, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9829742701002427, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9841175184817812, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9838970622330463, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9839666798550704, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9844191665202878, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.983276969138061, 'Test R2': 0.8...   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9845095776914405, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.984293032849126, 'Test R2': 0.8...   \n",
      "                             PowerTransformer     {'Train R2': 0.9846998978794109, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9851142009388936, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9850929913477112, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9840535848171882, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9844555098571616, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9849651365964975, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9845496232825498, 'Test R2': 0....   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.9842193972657068, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.984625147990609, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.9831428360814335, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9843923863865147, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9845351267981068, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9840485680405402, 'Test R2': 0....   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9829858941521927, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9834338365085772, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9848869016093865, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9841698435353893, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9841395101538536, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.984181626268167, 'Test R2': 0.8...   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9848213373183234, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9843206179202841, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9847222382000806, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9838061674082389, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9831712998934774, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9834421455785136, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9839368307247508, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9839113621024308, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9830933082871319, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9844320631217992, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9840545431381371, 'Test R2': 0....   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.9847177476728699, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9849560529647211, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9826928557789218, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.984427119925152, 'Test R2': 0.9...   \n",
      "                             QuantileTransformer  {'Train R2': 0.9845890357061765, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9847112417300913, 'Test R2': 0....   \n",
      "\n",
      "                                                                                            XGBoost  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9992276900639744, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9991884506725376, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9992229983272929, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9991616312947971, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9990432656607501, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9992641274844857, 'Test R2': 0....   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9992028388344926, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9992793381398862, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9993034467906478, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9991375332843825, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9993560518991947, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.999295711839136, 'Test R2': 0.9...   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9987363323300268, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9988954723043626, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9987836776763767, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9987777878616286, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9988554168140634, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9989481274453729, 'Test R2': 0....   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9991293797825902, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.999095981576203, 'Test R2': 0.8...   \n",
      "                             MinMaxScaler         {'Train R2': 0.9989675157500821, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9990564046804875, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9989805222853139, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9990356475757999, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9988752550424468, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.999177418732495, 'Test R2': 0.9...   \n",
      "                             MinMaxScaler         {'Train R2': 0.999029865077813, 'Test R2': 0.9...   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9988612792445416, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9990075145070094, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9990473296457589, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9989446420544178, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9989879593896445, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9992301428829473, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9988653619691722, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9990142437584683, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9993609821232384, 'Test R2': 0....   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.9991217673435742, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9991848853486095, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.999223172438755, 'Test R2': 0.9...   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9991550739942942, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9990583816613828, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9993474333047325, 'Test R2': 0....   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9987363323300268, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9988954723043626, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9987836776763767, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9987777878616286, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9988554168140634, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9989481274453729, 'Test R2': 0....   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.999224806203721, 'Test R2': 0.9...   \n",
      "                             RobustScaler         {'Train R2': 0.9993192603944332, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9991954799561457, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9992422674487679, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9991832470545037, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9992690818565719, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9987363323300268, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9988954723043626, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9987836776763767, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9987777878616286, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9988554168140634, 'Test R2': 0....   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.999239805321481, 'Test R2': 0.8...   \n",
      "                             RobustScaler         {'Train R2': 0.9992840029807941, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9991859486983447, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9991850055034367, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9990893272055003, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9991757930564116, 'Test R2': 0....   \n",
      "\n",
      "                                                                                           LightGBM  \\\n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9834608124243769, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9839589833698115, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.983490409901271, 'Test R2': 0.9...   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9837117293498394, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.983490409901271, 'Test R2': 0.9...   \n",
      "                             PowerTransformer     {'Train R2': 0.9832645462851964, 'Test R2': 0....   \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9829471816305453, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9839567383550608, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9827280069813574, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9833771167895908, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9827280069813574, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9837335426773507, 'Test R2': 0....   \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9837437128314644, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9834277455544779, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9835905530877349, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9826643983880117, 'Test R2': 0....   \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9836378091597132, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9838962654974642, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9829857518454895, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9831962137121576, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9829857518454895, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9836504512718692, 'Test R2': 0....   \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9830671222026918, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.983557348109637, 'Test R2': 0.9...   \n",
      "                             MinMaxScaler         {'Train R2': 0.9829366646191254, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9828134584045126, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9829366646191254, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9826207355727992, 'Test R2': 0....   \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9842817444466727, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9845060041786245, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9844173359681523, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.984649732130819, 'Test R2': 0.9...   \n",
      "                             QuantileTransformer  {'Train R2': 0.9844173359681523, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9846287704713619, 'Test R2': 0....   \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.9838780948914404, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9836607345639143, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9833907979526136, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9837612480025278, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9833907979526136, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9832893563409408, 'Test R2': 0....   \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9837437128314644, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9834277455544779, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9835905530877349, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9826643983880117, 'Test R2': 0....   \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9849337596814902, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9843967265146228, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9850922746951499, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9848798848793971, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9844919163068262, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9844086116376426, 'Test R2': 0....   \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9837437128314644, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9834277455544779, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9835905530877349, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9836887690248326, 'Test R2': 0....   \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.9852191572768487, 'Test R2': 0....   \n",
      "                             RobustScaler         {'Train R2': 0.9851861741543686, 'Test R2': 0....   \n",
      "                             MinMaxScaler         {'Train R2': 0.9842512602976682, 'Test R2': 0....   \n",
      "                             MaxAbsScaler         {'Train R2': 0.9841633410306808, 'Test R2': 0....   \n",
      "                             QuantileTransformer  {'Train R2': 0.9842512602976682, 'Test R2': 0....   \n",
      "                             PowerTransformer     {'Train R2': 0.9851783787032702, 'Test R2': 0....   \n",
      "\n",
      "                                                                                           CatBoost  \n",
      "Backward Difference Encoding StandardScaler       {'Train R2': 0.9936091186160108, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9936127260290364, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9936483605184976, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9935103489012002, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9937422273906051, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9935681185771588, 'Test R2': 0....  \n",
      "Binary Encoding              StandardScaler       {'Train R2': 0.9939164873263712, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.994152848178986, 'Test R2': 0.9...  \n",
      "                             MinMaxScaler         {'Train R2': 0.993982974526629, 'Test R2': 0.9...  \n",
      "                             MaxAbsScaler         {'Train R2': 0.994161076677158, 'Test R2': 0.9...  \n",
      "                             QuantileTransformer  {'Train R2': 0.9941507024763803, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9940000349673281, 'Test R2': 0....  \n",
      "Dummified Encoding           StandardScaler       {'Train R2': 0.9925336990630979, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9922968444419921, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9923020476464818, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9924002941858909, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9920247493454797, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.992423684179959, 'Test R2': 0.9...  \n",
      "Frequency Encoding           StandardScaler       {'Train R2': 0.9933145266247354, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9933528613494594, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9935772989571764, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9936372436797111, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9933318416152652, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9934383054069122, 'Test R2': 0....  \n",
      "Hashing Encoding             StandardScaler       {'Train R2': 0.9927341565055294, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9925623200781962, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9927213946757765, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9927429551613676, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9928362872156423, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9930045486424357, 'Test R2': 0....  \n",
      "Helmert Encoding             StandardScaler       {'Train R2': 0.9926484611096377, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9927705798568814, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.99262390446555, 'Test R2': 0.94...  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9924030108863588, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9926342786357212, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9936486849063064, 'Test R2': 0....  \n",
      "Label Encoding               StandardScaler       {'Train R2': 0.9936131660813241, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9936714003160932, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9934991053554493, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9932715973086119, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.993488544770947, 'Test R2': 0.9...  \n",
      "                             PowerTransformer     {'Train R2': 0.993709387317326, 'Test R2': 0.9...  \n",
      "One-Hot Encoding             StandardScaler       {'Train R2': 0.9925336990630979, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9922968444419921, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9923020476464818, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9924002941858909, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9920247493454797, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.992423684179959, 'Test R2': 0.9...  \n",
      "Polynomial Encoding          StandardScaler       {'Train R2': 0.9940130431247273, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9938820145441587, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9939762984249598, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9940635366091183, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9938723677051176, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.9943001354803297, 'Test R2': 0....  \n",
      "Sum Encoding                 StandardScaler       {'Train R2': 0.9923752474571192, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9923118601431135, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9922508245651942, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.9926815362420706, 'Test R2': 0....  \n",
      "                             QuantileTransformer  {'Train R2': 0.9922244243410221, 'Test R2': 0....  \n",
      "Target Encoding              StandardScaler       {'Train R2': 0.9937653356522919, 'Test R2': 0....  \n",
      "                             RobustScaler         {'Train R2': 0.9938930457820011, 'Test R2': 0....  \n",
      "                             MinMaxScaler         {'Train R2': 0.9940975865272182, 'Test R2': 0....  \n",
      "                             MaxAbsScaler         {'Train R2': 0.993642645867009, 'Test R2': 0.9...  \n",
      "                             QuantileTransformer  {'Train R2': 0.9939756759545255, 'Test R2': 0....  \n",
      "                             PowerTransformer     {'Train R2': 0.993970141892432, 'Test R2': 0.9...  \n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0),\n",
    "}\n",
    "\n",
    "# Define scalers\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"RobustScaler\": RobustScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler(),\n",
    "    \"MaxAbsScaler\": MaxAbsScaler(),\n",
    "    \"QuantileTransformer\": QuantileTransformer(),\n",
    "    \"PowerTransformer\": PowerTransformer(),\n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    return {\n",
    "        \"Train R2\": r2_score(y_train, predictions_train),\n",
    "        \"Test R2\": r2_score(y_test, predictions_test),\n",
    "        \"Train RMSE\": sqrt(mean_squared_error(y_train, predictions_train)),\n",
    "        \"Test RMSE\": sqrt(mean_squared_error(y_test, predictions_test)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, predictions_train),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, predictions_test),\n",
    "    }\n",
    "\n",
    "def prepare_and_evaluate(data, scaler):\n",
    "    # Prepare features and target\n",
    "    X = data.drop('SalePrice', axis=1)\n",
    "    y = data['SalePrice']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Apply scaler and check for infinities\n",
    "    try:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        if np.isinf(X_train).any() or np.isinf(X_test).any():\n",
    "            print('Infinities detected after scaling. Skipping this scaler...')\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}. Skipping this scaler...\")\n",
    "        return None\n",
    "\n",
    "    # Return the evaluation results\n",
    "    return {name: evaluate_model(model, X_train, X_test, y_train, y_test) for name, model in models.items()}\n",
    "\n",
    "# Define your encodings\n",
    "encodings = {\n",
    "    \"Backward Difference Encoding\": backward_difference_encoding,\n",
    "    \"Binary Encoding\": binary_encoding,\n",
    "    \"Dummified Encoding\": dummified_encoding,\n",
    "    \"Frequency Encoding\": frequency_encoding,\n",
    "    \"Hashing Encoding\": hashing_encoding,\n",
    "    \"Helmert Encoding\": helmert_encoding,\n",
    "    \"Label Encoding\": label_encoding,\n",
    "    \"One-Hot Encoding\": onehot_encoding_sklearn,\n",
    "    \"Polynomial Encoding\": polynomial_encoding,\n",
    "    \"Sum Encoding\": sum_encoding,\n",
    "    \"Target Encoding\": target_encoding\n",
    "}\n",
    "\n",
    "# Iterate over each encoding method and apply the prepare_and_evaluate function\n",
    "results = {}\n",
    "for encoding_name, encoded_data in encodings.items():\n",
    "    print(f\"Evaluating models with {encoding_name}...\")\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        print(f\"Applying {scaler_name} scaler...\")\n",
    "        result = prepare_and_evaluate(encoded_data, scaler)\n",
    "        if result is not None:\n",
    "            results[(encoding_name, scaler_name)] = result\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57197c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest R2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df.applymap(lambda x: x['Test R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37793d08",
   "metadata": {},
   "source": [
    "**catboost gridsearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "df261894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "Best parameters found:  {'depth': 6, 'iterations': 300, 'l2_leaf_reg': 3.0, 'learning_rate': 0.1}\n",
      "Best Parameters:  {'depth': 5, 'iterations': 1000, 'learning_rate': 0.09816326530612246}\n",
      "R2 Score:  0.9455520981362956\n",
      "Mean Absolute Error:  11824.194800996449\n",
      "Root Mean Squared Error:  18301.542853300514\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.1s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   2.4s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.5s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   4.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   4.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.1s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.5s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.5s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.9s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.1s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.5s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   3.5s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.8s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   4.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   4.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   4.2s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   2.4s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   2.8s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   2.9s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   5.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   4.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   5.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   5.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.7s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.2s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.0s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.5s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   3.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   2.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   3.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.9s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   3.5s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   3.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   5.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   5.2s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   5.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   2.4s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   2.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   3.6s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   3.6s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   4.5s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   4.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.8s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.4s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.4s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   2.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   2.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   2.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.4s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.9s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.9s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   4.5s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   5.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   4.5s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   5.0s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.6s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.4s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.2s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.7s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.5s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   2.0s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   2.6s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.1; total time=   2.1s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.5s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.6s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   3.0s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   3.1s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.1; total time=   3.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   4.6s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   4.9s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   4.7s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   4.8s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   4.8s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   0.6s\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.5s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   0.9s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.8s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.5s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.4s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=4, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=1.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=5.0, learning_rate=0.1; total time=   0.9s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.0s\n",
      "[CV] END depth=6, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   0.8s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   1.6s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=1.0, learning_rate=0.1; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   1.4s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.01; total time=   1.3s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=5.0, learning_rate=0.1; total time=   1.1s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.2s\n",
      "[CV] END depth=6, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   2.1s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=1.0, learning_rate=0.1; total time=   2.2s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=3.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.01; total time=   2.4s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=5.0, learning_rate=0.1; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=7.0, learning_rate=0.05500000000000001; total time=   1.9s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.01; total time=   2.0s\n",
      "[CV] END depth=6, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   2.3s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=1.0, learning_rate=0.05500000000000001; total time=   1.7s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.01; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=3.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.01; total time=   2.2s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=7.0, learning_rate=0.1; total time=   1.8s\n",
      "[CV] END depth=8, iterations=100, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   1.8s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=1.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.01; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=3.0, learning_rate=0.1; total time=   3.4s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   3.5s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.01; total time=   3.3s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=7.0, learning_rate=0.1; total time=   3.5s\n",
      "[CV] END depth=8, iterations=200, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   3.2s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=1.0, learning_rate=0.01; total time=   5.2s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.01; total time=   5.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=3.0, learning_rate=0.1; total time=   5.3s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=5.0, learning_rate=0.05500000000000001; total time=   5.2s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.01; total time=   5.1s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=7.0, learning_rate=0.1; total time=   4.5s\n",
      "[CV] END depth=8, iterations=300, l2_leaf_reg=9.0, learning_rate=0.05500000000000001; total time=   4.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostRegressor\n",
    "from numpy import sqrt\n",
    "from numpy import linspace\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your hyperparameters for CatBoost\n",
    "hyperparameters = {\n",
    "    \"iterations\": [100, 200, 300],\n",
    "    \"depth\": [int(x) for x in linspace(4, 8, 3)],\n",
    "    \"learning_rate\": linspace(0.01, 0.1, 3),\n",
    "    \"l2_leaf_reg\": linspace(1, 9, 5),\n",
    "}\n",
    "\n",
    "# Custom scoring function\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    # Change these weights to your liking\n",
    "    return r2 - (0.5 * rmse) - (0.5 * mae)\n",
    "\n",
    "scorer = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = helmert_encoding.drop('SalePrice', axis=1)\n",
    "y = helmert_encoding['SalePrice']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "# Cross-validation with shuffle\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=hyperparameters,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Scoring function for MAE\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Scoring function for RMSE\n",
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# Scoring function for R2\n",
    "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "\n",
    "# Dictionary of scorers\n",
    "scorers = {'r2': r2_scorer, 'mae': mae_scorer, 'rmse': rmse_scorer}\n",
    "\n",
    "# More robust parameters for grid search\n",
    "param_grid = {\n",
    "    'iterations': [500, 1000],\n",
    "    'depth': [3, 5],\n",
    "    'learning_rate': np.linspace(.1,0.01),\n",
    "}\n",
    "\n",
    "# Grid search with CatBoost\n",
    "model = CatBoostRegressor(loss_function='RMSE', verbose=0)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=scorers, refit='r2', n_jobs=-1)\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Fit the model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the metrics\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: \", sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5147af6",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f7832",
   "metadata": {},
   "source": [
    "**mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9b9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d756bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "           'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', \n",
    "           'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', \n",
    "           'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', \n",
    "           'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "           'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "\n",
    "for column in columns:\n",
    "    # Group the data by the column and calculate the mean of 'SalePrice' for each group\n",
    "    average_price_per_group = mapped.groupby(column)['SalePrice'].mean()\n",
    "\n",
    "    # Convert the Series to a DataFrame for better visualization\n",
    "    average_price_per_group_df = average_price_per_group.reset_index()\n",
    "\n",
    "    # Rename the columns\n",
    "    average_price_per_group_df.columns = [column, 'AverageSalePrice']\n",
    "\n",
    "    # Sort the DataFrame by 'AverageSalePrice'\n",
    "    sorted_df = average_price_per_group_df.sort_values('AverageSalePrice')\n",
    "\n",
    "    # Create a dictionary mapping the column to a number from 0 to 100\n",
    "    column_map = {value: i * 100 / (len(sorted_df) - 1) for i, value in enumerate(sorted_df[column])}\n",
    "\n",
    "    # Map 'column_map' to the column in 'mapped'\n",
    "    mapped[column] = mapped[column].map(column_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dff040d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CatBoost ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9239180682001885 (+/- 0.031382077108684556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelminer/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 11805.441275523019\n",
      "RMSE: 19179.4806122383\n",
      "---- LightGBM ----\n",
      "R2: 0.8982629898647311 (+/- 0.0343635142854992)\n",
      "MAE: 13675.97102599661\n",
      "RMSE: 22441.155910022426\n",
      "---- XGBoost ----\n",
      "R2: 0.8838609148064183 (+/- 0.04145573945419561)\n",
      "MAE: 14791.76121154312\n",
      "RMSE: 24064.01102436959\n",
      "---- GradientBoosting ----\n",
      "R2: 0.8966009354339665 (+/- 0.07593895446944447)\n",
      "MAE: 14314.186502177925\n",
      "RMSE: 23247.13992148043\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "X = mapped.drop(columns='SalePrice')\n",
    "y = mapped['SalePrice']\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Define cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X, y):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "    print(f\"R2: {cv_scores.mean()} (+/- {cv_scores.std() * 2})\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, predictions)}\")\n",
    "    print(f\"RMSE: {sqrt(mean_squared_error(y_test, predictions))}\")\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"---- {name} ----\")\n",
    "    evaluate_model(model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60f3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
